{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif,  chi2\n",
    "from sklearn import svm\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom1 = []\n",
    "dom2 = []\n",
    "test_set = []\n",
    "with open('data/domain1_train.json', 'r') as file:\n",
    "    for line in file:\n",
    "        dom1.append(json.loads(line))\n",
    "        \n",
    "with open('data/domain2_train.json', 'r') as file:\n",
    "    for line in file:\n",
    "        dom2.append(json.loads(line))\n",
    "        \n",
    "sam = pd.read_csv(\"data/sample.csv\")\n",
    "\n",
    "with open('data/test_set.json', 'r') as file:\n",
    "    for line in file:\n",
    "        test_set.append(json.loads(line))\n",
    "        \n",
    "dom1 = pd.DataFrame.from_dict(dom1)\n",
    "dom2 = pd.DataFrame.from_dict(dom2)\n",
    "dom2 = dom2[dom2['text'].apply(len) > 0]\n",
    "test_set = pd.DataFrame.from_dict(test_set)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19500\n",
      "14899\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(dom1))\n",
    "print(len(dom2))\n",
    "print(len(sam))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12750\n",
      "2149\n"
     ]
    }
   ],
   "source": [
    "dom1['label'].value_counts()\n",
    "print(len(dom2.loc[dom2['label']==0]))\n",
    "print(len(dom2.loc[dom2['label']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dom2_0 = dom2.loc[dom2['label']==0]\n",
    "dom2_1 = dom2.loc[dom2['label']==1]\n",
    "\n",
    "length_dom2_1 = len(dom2_1)\n",
    "mol_num = len(dom2['model'].value_counts())\n",
    "sam_dom2_0 = dom2_0.groupby('model').apply(lambda x: x.sample(n=int(length_dom2_1/mol_num)))\n",
    "sam_dom2_0.reset_index(drop=True, inplace=True)\n",
    "dom2_new = result = pd.concat([dom2_1, sam_dom2_0])\n",
    "\n",
    "sampled_dom1 = dom1.groupby('label').apply(lambda x: x.sample(n=int(length_dom2_1/mol_num)))\n",
    "sampled_dom1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data = result = pd.concat([sampled_dom1, dom2_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data['model'].fillna(8, inplace=True)\n",
    "\n",
    "\n",
    "X = data[['text','model']] \n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=data[['model', 'label']], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1640    0\n",
       "227     0\n",
       "631     0\n",
       "1887    0\n",
       "1576    0\n",
       "       ..\n",
       "1445    0\n",
       "2014    0\n",
       "694     1\n",
       "360     1\n",
       "374     0\n",
       "Name: label, Length: 3929, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    0.500127\n",
      "1    0.499873\n",
      "Name: proportion, dtype: float64\n",
      "label\n",
      "1    0.500509\n",
      "0    0.499491\n",
      "Name: proportion, dtype: float64\n",
      "model\n",
      "8.0    0.562484\n",
      "5.0    0.062611\n",
      "0.0    0.062611\n",
      "2.0    0.062611\n",
      "1.0    0.062611\n",
      "6.0    0.062357\n",
      "4.0    0.062357\n",
      "3.0    0.062357\n",
      "Name: proportion, dtype: float64\n",
      "model\n",
      "8.0    0.562564\n",
      "4.0    0.063072\n",
      "6.0    0.063072\n",
      "3.0    0.063072\n",
      "2.0    0.062055\n",
      "0.0    0.062055\n",
      "5.0    0.062055\n",
      "1.0    0.062055\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "print(X_train['model'].value_counts(normalize=True))\n",
    "print(X_test['model'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = X_train['text'].tolist()\n",
    "X1 =X_test['text'].tolist()\n",
    "max_length = max([len(seq) for seq in X])\n",
    "word2vec = Word2Vec(X, vector_size=300, window=10, min_count=1, workers=4)\n",
    "\n",
    "def get_text_vector(text, word2vec_model):\n",
    "    vector_list = [word2vec_model.wv[word] for word in text if word in word2vec_model.wv.index_to_key]\n",
    "    if len(vector_list) == 0:\n",
    "        return np.zeros(word2vec.vector_size)\n",
    "    return np.mean(vector_list, axis=0)\n",
    "\n",
    "X_train = np.array([get_text_vector(text, word2vec) for text in X])\n",
    "X_test = np.array([get_text_vector(text, word2vec) for text in X1])\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    0.500127\n",
      "1    0.499873\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.6948118006103764\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"Test score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  class\n",
       "0      0      1\n",
       "1      1      0\n",
       "2      2      0\n",
       "3      3      0\n",
       "4      4      0\n",
       "..   ...    ...\n",
       "995  995      0\n",
       "996  996      1\n",
       "997  997      0\n",
       "998  998      1\n",
       "999  999      1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 =test_set['text'].tolist()\n",
    "test_set = np.array([get_text_vector(text, word2vec) for text in X2])\n",
    "test_pre = model.predict(test_set)\n",
    "result = pd.DataFrame({\n",
    "    'class': test_pre,\n",
    "})\n",
    "result['id'] = result.index\n",
    "result = result[['id'] + [col for col in result.columns if col != 'id']]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result1.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a90aeebcf29d64a654773811cc170cb25061cb2498f10ac689db374c7bf325de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
